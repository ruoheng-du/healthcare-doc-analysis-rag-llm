import streamlit as st
from PIL import Image
from pathlib import Path
import sys

# ============================================================
# ========== PATH SETUP ======================================
# ============================================================
st.set_page_config(page_title="NYS Policies Assistant", layout="wide")

ROOT = Path(__file__).resolve().parents[1]  # project root
SRC_DIR = ROOT / "src"
sys.path.append(str(SRC_DIR))  # allow import from src/

# ============================================================
# ========== IMPORT PIPELINE MODULES =========================
# ============================================================
try:
    from healthcare_rag_llm.llm.llm_client import LLMClient
    from healthcare_rag_llm.llm.response_generator import ResponseGenerator
    HAS_BACKEND = True
except Exception as e:
    HAS_BACKEND = False
    # st.warning(f"‚ö†Ô∏è Backend import failed: {e}. Mock mode enabled.")


# ============================================================
# ========== STREAMLIT PAGE CONFIG ===========================
# ============================================================

# Paths
ROOT_DIR = Path(__file__).parent
ASSETS_DIR = ROOT_DIR / "assets"
nys_logo_path = ASSETS_DIR / "nys_logo.png"

# ============================================================
# ========== HEADER ==========================================
# ============================================================
col1, col2 = st.columns([5, 1])
with col1:
    st.title("NYS Policies Assistant")
    st.caption("An AI-powered assistant for navigating New York State medical care policies.")
with col2:
    if nys_logo_path.exists():
        nys_logo = Image.open(nys_logo_path)
        st.image(nys_logo, width=200)
    else:
        st.text("NYS Logo Missing")

# ============================================================
# ========== DISCLAIMER ======================================
# ============================================================
with st.expander("üìú Disclaimer & About", expanded=True):
    st.markdown("""
    This assistant is part of the **Columbia University x KPMG Capstone Project**:
    *Intelligent Document Analysis for Healthcare Programs Using LLMs and RAG.*

    The responses are generated by an AI model referencing official
    New York State Medicaid documents and related authorities.
    They do not constitute legal advice.
    """)

# ============================================================
# ========== INITIALIZE RAG PIPELINE =========================
# ============================================================
@st.cache_resource
def load_rag_pipeline():
    if not HAS_BACKEND:
        return None
    llm_client = LLMClient(
        api_key="",  # API key
        model="gpt-5",
        provider="openai",
        base_url="https://api.bltcy.ai/v1"
    )
    return ResponseGenerator(llm_client)

rag_pipeline = load_rag_pipeline()

# ============================================================
# ========== CHAT MODE (Single Q&A) ==========================
# ============================================================
# st.markdown("### üîç Ask a Question")
# user_query = st.text_area(
#     "Enter your question here:",
#     placeholder="e.g. When did redetermination begin for the COVID-19 Public Health Emergency unwind in New York State?"
# )

# if st.button("Submit"):
#     if not user_query.strip():
#         st.warning("Please enter a question before submitting.")
#     else:
#         with st.spinner("Retrieving information..."):
#             try:
#                 if rag_pipeline:
#                     # --- Real backend mode ---
#                     result = rag_pipeline.answer_question(user_query)
#                     answer = result.get("answer", "No answer returned.")
#                     retrieved_docs = result.get("retrieved_docs", [])

#                     st.success("‚úÖ Answer Retrieved")
#                     st.markdown(f"**Answer:**\n\n{answer}")

#                     st.markdown("### üìö Retrieved Sources")
#                     if retrieved_docs:
#                         for doc in retrieved_docs:
#                             doc_id = doc.get("doc_id", "Unknown")
#                             pages = doc.get("pages", "N/A")
#                             snippet = doc.get("text", "")[:300]
#                             st.markdown(f"- **{doc_id}** (pages {pages})")
#                             st.caption(snippet + "...")
#                     else:
#                         st.caption("No source documents retrieved.")
#                 else:
#                     # --- Mock mode (no backend) ---
#                     st.warning("‚ö†Ô∏è Mock mode: Backend not connected.")
#                     st.markdown(
#                         "The assistant is currently running in mock mode without a live RAG backend. "
#                         "Please connect to the backend to generate answers."
#                     )

#             except Exception as e:
#                 st.error(f"Error: {e}")

# ============================================================
# ========== CHAT MODE (Multiple Q&A) ========================
# ============================================================

# Initialize history
if "history" not in st.session_state:
    st.session_state["history"] = []  # per history: {"role": "user"/"assistant", "content": "..."}
    
# Input
user_query = st.text_input(
    "üîç Ask a Question:",
    placeholder="e.g. When did redetermination begin for the COVID-19 Public Health Emergency unwind in New York State?"
)

col_send, col_clear = st.columns([1, 1])
with col_send:
    submit = st.button("Submit")
with col_clear:
    if st.button("Clear Chat"):
        st.session_state["history"] = []
        st.rerun()

# Display history
for msg in st.session_state["history"]:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    else:
        st.chat_message("assistant").write(msg["content"])

# New question
if submit:
    if not user_query.strip():
         st.warning("Please enter a question before submitting.")
    else:
        # Save user input
        st.session_state["history"].append({"role": "user", "content": user_query})
        with st.spinner("Retrieving information..."):
            try:
                if rag_pipeline:
                    # --- Real backend ---
                    result = rag_pipeline.answer_question(user_query)
                    answer = result.get("answer", "No answer returned.")
                    retrieved_docs = result.get("retrieved_docs", [])

                    st.success("‚úÖ Answer Retrieved")
                    st.markdown(f"**Answer:**\n\n{answer}")

                    st.markdown("### üìö Retrieved Sources")
                    if retrieved_docs:
                        for doc in retrieved_docs:
                            doc_id = doc.get("doc_id", "Unknown")
                            pages = doc.get("pages", "N/A")
                            snippet = doc.get("text", "")[:300]
                            st.markdown(f"- **{doc_id}** (pages {pages})")
                            st.caption(snippet + "...")
                    else:
                        st.caption("No source documents retrieved.")
                else:
                    # --- Mock mode ---
                    answer = (
                        "‚ö†Ô∏è Mock mode: Backend not connected.\n"
                        "No grounded answer can be generated. "
                        "Please connect the backend (RAG pipeline) to enable cited answers."
                    )
                    st.warning("‚ö†Ô∏è Mock mode: Backend not connected.")
                    st.markdown(
                        "The assistant is currently running in mock mode without a live RAG backend. "
                        "Please connect to the backend to generate answers."
                    )

                # Save answers
                st.session_state["history"].append({"role": "assistant", "content": answer})
                st.rerun()

            except Exception as e:
                st.error(f"Error: {e}")


# ============================================================
# ========== FOOTER ==========================================
# ============================================================
st.divider()
st.markdown(
    "<p style='font-size: small; color: gray;'>¬© 2025 Columbia DSI x KPMG | For educational use only.</p>",
    unsafe_allow_html=True
)